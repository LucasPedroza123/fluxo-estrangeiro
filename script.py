import pandas as pd
import requests
from bs4 import BeautifulSoup
import gspread
from oauth2client.service_account import ServiceAccountCredentials
import json
import os

# ðŸŸ¢ Criar o arquivo JSON com credenciais a partir do Secret (caso esteja rodando no GitHub Actions)
CREDENTIALS_PATH = "credentials.json"

if not os.path.exists(CREDENTIALS_PATH):
    with open(CREDENTIALS_PATH, "w") as cred_file:
        cred_file.write(os.getenv("GOOGLE_SHEETS_CREDENTIALS", ""))

# ðŸŸ¢ ConfiguraÃ§Ã£o da API do Google Sheets
scope = ["https://spreadsheets.google.com/feeds", "https://www.googleapis.com/auth/drive"]
credenciais = ServiceAccountCredentials.from_json_keyfile_name(CREDENTIALS_PATH, scope)
cliente = gspread.authorize(credenciais)

# ðŸŸ¢ Abrir a planilha no Google Sheets
spreadsheet = cliente.open_by_url("https://docs.google.com/spreadsheets/d/1aiaG9InWCYqbb7KP7QG6s7ixCSmdMWuKAdjIeimpQcg/edit?gid=0#gid=0")
sheet = spreadsheet.worksheet("AbaFluxo")  # Nome da aba no Google Sheets

# ðŸŸ¢ URL do site para obter os dados
url = "https://www.dadosdemercado.com.br/fluxo"

# ðŸŸ¢ Fazer a requisiÃ§Ã£o HTTP para obter o HTML da pÃ¡gina
headers = {"User-Agent": "Mozilla/5.0"}
response = requests.get(url, headers=headers)
soup = BeautifulSoup(response.text, "html.parser")

# ðŸŸ¢ Encontrar a tabela de fluxo de mercado no site
tabela_html = soup.find("table")

# ðŸŸ¢ Converter a tabela para um DataFrame do Pandas
import io
df = pd.read_html(io.StringIO(str(tabela_html)))[0]

# ðŸŸ¢ Atualizar a planilha no Google Sheets
sheet.clear()  # Limpa os dados antigos
sheet.update([df.columns.values.tolist()] + df.values.tolist())  # Adiciona os novos dados

print("âœ… Planilha do Google Sheets atualizada com sucesso!")
